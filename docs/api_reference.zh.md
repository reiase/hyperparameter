# API å‚è€ƒæ–‡æ¡£

æœ¬æ–‡æ¡£æä¾› Hyperparameter Python API çš„å®Œæ•´å‚è€ƒã€‚

---

## param_scope

`param_scope` æ˜¯ç®¡ç†è¶…å‚æ•°çš„æ ¸å¿ƒç±»ï¼Œæä¾›çº¿ç¨‹å®‰å…¨çš„ä½œç”¨åŸŸæ§åˆ¶ã€‚

### å¯¼å…¥

```python
from hyperparameter import param_scope
```

### åˆ›å»º param_scope

```python
# ç©ºä½œç”¨åŸŸ
ps = param_scope()

# ä»å…³é”®å­—å‚æ•°åˆ›å»º
ps = param_scope(lr=0.001, batch_size=32)

# ä»å­—ç¬¦ä¸²å‚æ•°åˆ›å»ºï¼ˆkey=value æ ¼å¼ï¼‰
ps = param_scope("lr=0.001", "batch_size=32")

# ä»å­—å…¸åˆ›å»º
ps = param_scope(**{"train.lr": 0.001, "train.batch_size": 32})

# ç©ºä½œç”¨åŸŸï¼ˆæ¸…é™¤ç»§æ‰¿çš„å€¼ï¼‰
ps = param_scope.empty()
ps = param_scope.empty(lr=0.001)
```

### è¯»å–å‚æ•°

```python
# ä½¿ç”¨ | è¿ç®—ç¬¦ï¼ˆç¼ºå¤±æ—¶è¿”å›é»˜è®¤å€¼ï¼‰
lr = param_scope.train.lr | 0.001

# ä½¿ç”¨å‡½æ•°è°ƒç”¨ï¼ˆç¼ºå¤±æ—¶è¿”å›é»˜è®¤å€¼ï¼‰
lr = param_scope.train.lr(0.001)

# æ— é»˜è®¤å€¼ï¼ˆç¼ºå¤±æ—¶æŠ›å‡º KeyErrorï¼‰
lr = param_scope.train.lr()

# åŠ¨æ€ key è®¿é—®
key = "train.lr"
lr = param_scope[key] | 0.001
```

### å†™å…¥å‚æ•°

```python
with param_scope() as ps:
    # å±æ€§èµ‹å€¼
    param_scope.train.lr = 0.001
    
    # é€šè¿‡å®ä¾‹
    ps.train.batch_size = 32
```

### ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆwith è¯­å¥ï¼‰

```python
# åŸºæœ¬ç”¨æ³•
with param_scope(**{"lr": 0.001}):
    print(param_scope.lr())  # 0.001

# åµŒå¥—ä½œç”¨åŸŸ
with param_scope(**{"a": 1}):
    print(param_scope.a())  # 1
    with param_scope(**{"a": 2}):
        print(param_scope.a())  # 2
    print(param_scope.a())  # 1ï¼ˆè‡ªåŠ¨å›æ»šï¼‰
```

### é™æ€æ–¹æ³•

#### `param_scope.empty(*args, **kwargs)`

åˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºä½œç”¨åŸŸï¼Œæ¸…é™¤æ‰€æœ‰ç»§æ‰¿çš„å€¼ã€‚

```python
with param_scope(**{"inherited": 1}):
    with param_scope.empty(**{"fresh": 2}) as ps:
        print(ps.inherited("missing"))  # "missing"
        print(ps.fresh())  # 2
```

#### `param_scope.current()`

è¿”å›å½“å‰æ´»åŠ¨çš„ä½œç”¨åŸŸã€‚

```python
with param_scope(**{"key": "value"}):
    ps = param_scope.current()
    print(ps.key())  # "value"
```

#### `param_scope.frozen()`

å°†å½“å‰ä½œç”¨åŸŸå¿«ç…§ä¸ºæ–°çº¿ç¨‹çš„å…¨å±€åŸºçº¿ã€‚

```python
with param_scope(**{"global_config": 42}):
    param_scope.frozen()
    # æ–°çº¿ç¨‹å°†ç»§æ‰¿ global_config=42
```

#### `param_scope.init(params=None)`

ä¸ºæ–°çº¿ç¨‹åˆå§‹åŒ– param_scopeã€‚

```python
def thread_target():
    param_scope.init({"thread_param": 1})
    # ...
```

### å®ä¾‹æ–¹æ³•

#### `ps.keys()`

è¿”å›æ‰€æœ‰å‚æ•° key çš„å¯è¿­ä»£å¯¹è±¡ã€‚

```python
with param_scope(**{"a": 1, "b.c": 2}) as ps:
    print(list(ps.keys()))  # ['a', 'b.c']
```

#### `ps.storage()`

è¿”å›åº•å±‚å­˜å‚¨å¯¹è±¡ã€‚

#### `ps.update(dict)`

ä½¿ç”¨å­—å…¸æ›´æ–°ä½œç”¨åŸŸã€‚

#### `ps.clear()`

æ¸…é™¤å½“å‰ä½œç”¨åŸŸä¸­çš„æ‰€æœ‰å‚æ•°ã€‚

---

## @auto_param

è£…é¥°å™¨ï¼Œè‡ªåŠ¨å°†å‡½æ•°å‚æ•°ç»‘å®šåˆ°è¶…å‚æ•°ã€‚

### å¯¼å…¥

```python
from hyperparameter import auto_param
```

### åŸºæœ¬ç”¨æ³•

```python
@auto_param("train")
def train(lr=0.001, batch_size=32, epochs=10):
    print(f"lr={lr}, batch_size={batch_size}")

# ä½¿ç”¨å‡½æ•°é»˜è®¤å€¼
train()  # lr=0.001, batch_size=32

# é€šè¿‡ param_scope è¦†ç›–
with param_scope(**{"train.lr": 0.01}):
    train()  # lr=0.01, batch_size=32

# ç›´æ¥ä¼ å‚ä¼˜å…ˆçº§æœ€é«˜
train(lr=0.1)  # lr=0.1, batch_size=32
```

### è‡ªå®šä¹‰å‘½åç©ºé—´

```python
@auto_param("myapp.config.train")
def train(lr=0.001):
    print(f"lr={lr}")

with param_scope(**{"myapp.config.train.lr": 0.01}):
    train()  # lr=0.01
```

### æ— å‘½åç©ºé—´ï¼ˆä½¿ç”¨å‡½æ•°åï¼‰

```python
@auto_param
def my_function(x=1):
    return x

with param_scope(**{"my_function.x": 2}):
    my_function()  # è¿”å› 2
```

### ç±»è£…é¥°å™¨

```python
@auto_param("Model")
class Model:
    def __init__(self, hidden_size=256, dropout=0.1):
        self.hidden_size = hidden_size
        self.dropout = dropout

with param_scope(**{"Model.hidden_size": 512}):
    model = Model()  # hidden_size=512, dropout=0.1
```

### å‚æ•°è§£æä¼˜å…ˆçº§

1. **ç›´æ¥ä¼ å‚**ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
2. **param_scope è¦†ç›–**
3. **å‡½æ•°ç­¾åé»˜è®¤å€¼**ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰

---

## launch

CLI åº”ç”¨ç¨‹åºå…¥å£ï¼Œæ”¯æŒè‡ªåŠ¨å‚æ•°è§£æã€‚

### å¯¼å…¥

```python
from hyperparameter import launch
```

### å•å‡½æ•°æ¨¡å¼

```python
@auto_param("app")
def main(input_file, output_file="out.txt", verbose=False):
    """å¤„ç†è¾“å…¥æ–‡ä»¶ã€‚
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        verbose: å¯ç”¨è¯¦ç»†è¾“å‡º
    """
    pass

if __name__ == "__main__":
    launch(main)
```

è¿è¡Œï¼š
```bash
python app.py input.txt --output_file result.txt --verbose
python app.py input.txt -D app.verbose=true
```

### å¤šå‡½æ•°æ¨¡å¼ï¼ˆå­å‘½ä»¤ï¼‰

```python
@auto_param("train")
def train(epochs=10, lr=0.001):
    """è®­ç»ƒæ¨¡å‹ã€‚"""
    pass

@auto_param("eval")
def evaluate(checkpoint="model.pt"):
    """è¯„ä¼°æ¨¡å‹ã€‚"""
    pass

if __name__ == "__main__":
    launch()  # è‡ªåŠ¨å‘ç°æ‰€æœ‰ @auto_param å‡½æ•°
```

è¿è¡Œï¼š
```bash
python app.py train --epochs 20
python app.py eval --checkpoint best.pt
```

### CLI é€‰é¡¹

| é€‰é¡¹ | è¯´æ˜ |
|------|------|
| `-D, --define KEY=VALUE` | è¦†ç›–è¶…å‚æ•° |
| `-lps, --list-param-scope` | åˆ—å‡ºæ‰€æœ‰æ³¨å†Œçš„å‚æ•° |
| `-ep, --explain-param KEY` | æ˜¾ç¤ºå‚æ•°è¯¦æƒ… |
| `-h, --help` | æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ |

---

## run_cli

`launch` çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè¡Œä¸ºç•¥æœ‰ä¸åŒã€‚

```python
from hyperparameter import run_cli

if __name__ == "__main__":
    run_cli()
```

---

## ç±»å‹è½¬æ¢

è¯»å–å‚æ•°æ—¶ï¼Œä¼šæ ¹æ®é»˜è®¤å€¼çš„ç±»å‹è‡ªåŠ¨è¿›è¡Œç±»å‹è½¬æ¢ã€‚

### å¸ƒå°”å€¼è½¬æ¢

```python
with param_scope(**{"flag": "true"}):
    param_scope.flag(False)  # True

# è¯†åˆ«çš„çœŸå€¼: "true", "True", "TRUE", "t", "T", "yes", "YES", "y", "Y", "1", "on", "ON"
# è¯†åˆ«çš„å‡å€¼: "false", "False", "FALSE", "f", "F", "no", "NO", "n", "N", "0", "off", "OFF"
```

### æ•´æ•°è½¬æ¢

```python
with param_scope(**{"count": "42"}):
    param_scope.count(0)  # 42 (int)

with param_scope(**{"value": "3.14"}):
    param_scope.value(0)  # 3.14 (floatï¼Œä¿ç•™ç²¾åº¦)
```

### æµ®ç‚¹æ•°è½¬æ¢

```python
with param_scope(**{"rate": "0.001"}):
    param_scope.rate(0.0)  # 0.001
```

### å­—ç¬¦ä¸²è½¬æ¢

```python
with param_scope(**{"count": 42}):
    param_scope.count("0")  # "42" (string)
```

---

## çº¿ç¨‹å®‰å…¨

### çº¿ç¨‹éš”ç¦»

æ¯ä¸ªçº¿ç¨‹æœ‰è‡ªå·±çš„å‚æ•°ä½œç”¨åŸŸï¼Œä¸€ä¸ªçº¿ç¨‹çš„ä¿®æ”¹ä¸ä¼šå½±å“å…¶ä»–çº¿ç¨‹ã€‚

```python
import threading

def worker():
    with param_scope(**{"worker_id": threading.current_thread().name}):
        print(param_scope.worker_id())

threads = [threading.Thread(target=worker) for _ in range(3)]
for t in threads:
    t.start()
for t in threads:
    t.join()
```

### ä¼ æ’­åˆ°æ–°çº¿ç¨‹

ä½¿ç”¨ `frozen()` å°†å€¼ä¼ æ’­åˆ°æ–°çº¿ç¨‹ï¼š

```python
with param_scope(**{"global_config": 42}):
    param_scope.frozen()

def worker():
    print(param_scope.global_config())  # 42

t = threading.Thread(target=worker)
t.start()
t.join()
```

---

## é”™è¯¯å¤„ç†

### KeyError

è®¿é—®ç¼ºå¤±çš„å¿…éœ€å‚æ•°æ—¶æŠ›å‡ºï¼š

```python
with param_scope():
    param_scope.missing()  # æŠ›å‡º KeyError
```

### å®‰å…¨è®¿é—®

å§‹ç»ˆæä¾›é»˜è®¤å€¼ä»¥é¿å… KeyErrorï¼š

```python
with param_scope():
    param_scope.missing | "default"  # è¿”å› "default"
    param_scope.missing("default")   # è¿”å› "default"
```

---

## é«˜çº§ç‰¹æ€§

### åµŒå¥—å­—å…¸å±•å¹³

åµŒå¥—å­—å…¸ä¼šè‡ªåŠ¨å±•å¹³ï¼š

```python
with param_scope(**{"model": {"hidden": 256, "layers": 4}}):
    print(param_scope["model.hidden"]())  # 256
    print(param_scope.model.layers())     # 4
```

### åŠ¨æ€ key æ„é€ 

```python
for task in ["train", "eval"]:
    key = f"config.{task}.batch_size"
    value = getattr(param_scope.config, task).batch_size | 32
```

### è®¿é—®åº•å±‚å­˜å‚¨

```python
with param_scope(**{"a": 1, "b": 2}) as ps:
    storage = ps.storage()
    print(storage.storage())  # {'a': 1, 'b': 2}
```

---

## Rust æ¥å£

### with_params! å®

```rust
use hyperparameter::*;

fn main() {
    with_params! {
        // è®¾ç½®å‚æ•°
        set train.lr = 0.001f64;
        set train.batch_size = 32i64;
        
        // è¯»å–å‚æ•°
        get lr = train.lr or 0.001f64;
        get batch_size = train.batch_size or 32i64;
        
        println!("lr={}, batch_size={}", lr, batch_size);
    };
}
```

### å‚æ•°è®¾ç½®

```rust
with_params! {
    set key = value;  // è®¾ç½®å‚æ•°
}
```

### å‚æ•°è¯»å–

```rust
with_params! {
    get var = key or default;  // è¯»å–å‚æ•°ï¼Œæä¾›é»˜è®¤å€¼
}
```

### frozen()

```rust
with_params! {
    set global.config = 42i64;
    frozen();  // å¿«ç…§ä¸ºå…¨å±€åŸºçº¿
};
```

### ParamScope

```rust
use hyperparameter::ParamScope;

let ps = ParamScope::from(&["key=value".to_string()]);
with_params! {
    params ps;
    // ...
};
```

---

## å­˜å‚¨åç«¯

### Python åç«¯

çº¯ Python å®ç°ï¼Œä½¿ç”¨ `ContextVar` å®ç°çº¿ç¨‹å®‰å…¨ã€‚

### Rust åç«¯

é«˜æ€§èƒ½ Rust å®ç°ï¼Œæä¾›ï¼š
- ç¼–è¯‘æ—¶ key å“ˆå¸Œ
- æ›´å¿«çš„å‚æ•°è®¿é—®
- è·¨è¯­è¨€ä¸€è‡´æ€§

æ£€æŸ¥åç«¯ï¼š

```python
from hyperparameter.storage import has_rust_backend
print(has_rust_backend)  # True/False
```

å¼ºåˆ¶ä½¿ç”¨ Python åç«¯ï¼š

```bash
export HYPERPARAMETER_BACKEND=PYTHON
```

---

## å‘½ä»¤è¡Œå·¥å…·ï¼šhp

Hyperparameter æä¾› `hp` å‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºåˆ†æ Python åŒ…ä¸­çš„è¶…å‚æ•°ä½¿ç”¨æƒ…å†µã€‚

### å®‰è£…

å®‰è£… hyperparameter åï¼Œ`hp` å‘½ä»¤å³å¯ä½¿ç”¨ï¼š

```bash
pip install hyperparameter
hp --help
```

### å‘½ä»¤

#### hp list / hp ls

åˆ—å‡ºè¶…å‚æ•°ï¼š

```bash
# åˆ—å‡ºæ‰€æœ‰ä½¿ç”¨ hyperparameter çš„åŒ…
hp ls
hp list

# åˆ—å‡ºåŒ…ä¸­çš„è¶…å‚æ•°
hp ls mypackage

# æ ‘çŠ¶æ˜¾ç¤º
hp ls mypackage --tree
hp ls mypackage -t

# èŒƒå›´é€‰é¡¹
hp ls mypackage --self       # ä»…è‡ªèº«ï¼ˆé»˜è®¤ï¼‰
hp ls mypackage --all        # åŒ…å«ä¾èµ–
hp ls mypackage --deps       # ä»…ä¾èµ–

# è¾“å‡ºæ ¼å¼
hp ls mypackage -f text      # é»˜è®¤æ–‡æœ¬æ ¼å¼
hp ls mypackage -f markdown  # Markdown æ ¼å¼
hp ls mypackage -f json      # JSON æ ¼å¼

# ä¿å­˜åˆ°æ–‡ä»¶
hp ls mypackage -o report.md -f markdown
```

#### åŒ…å‘ç°

ä¸å¸¦å‚æ•°è¿è¡Œ `hp ls` æ—¶ï¼Œä¼šæ‰«ææ‰€æœ‰å·²å®‰è£…çš„åŒ…ï¼š

```
Packages using hyperparameter (3):
============================================================
Package                        Version      Params   Funcs
------------------------------------------------------------
myapp                          1.0.0        15       5
ml-toolkit                     0.2.1        8        3
config-manager                 2.1.0        4        2
------------------------------------------------------------

Use 'hp ls <package>' to see hyperparameters in a package.
```

#### hp describe / hp desc

æŸ¥çœ‹è¶…å‚æ•°è¯¦æƒ…ï¼š

```bash
# ç²¾ç¡®åŒ¹é…
hp desc train.lr mypackage

# æ¨¡ç³Šæœç´¢
hp desc lr mypackage

# é»˜è®¤å½“å‰ç›®å½•
hp desc train.lr
```

### ç¤ºä¾‹è¾“å‡º

#### åˆ—è¡¨ï¼ˆæ ‘çŠ¶è§†å›¾ï¼‰

```
Hyperparameters in myapp:
----------------------------------------
ğŸ“ train
  ğŸ“„ lr = 0.001
  ğŸ“„ batch_size = 32
  ğŸ“„ epochs = 10
ğŸ“ model
  ğŸ“„ hidden_size = 256
  ğŸ“„ dropout = 0.1

Total: 5 hyperparameters
```

#### æè¿°

```
============================================================
Hyperparameter: train.lr
============================================================

  Default: 0.001
  Type: float
  Namespace: train
  Function: train

  Source: myapp
  Location: train.py:15

  Description: Training function with configurable learning rate.

  Usage:
    # é€šè¿‡ param_scope è®¿é—®
    value = param_scope.train.lr | <default>
    
    # é€šè¿‡å‘½ä»¤è¡Œè®¾ç½®
    --train.lr=<value>
```

### ä½¿ç”¨åœºæ™¯

1. **é¡¹ç›®å®¡è®¡**ï¼šå¿«é€Ÿäº†è§£é¡¹ç›®ä¸­æ‰€æœ‰å¯é…ç½®çš„è¶…å‚æ•°
2. **æ–‡æ¡£ç”Ÿæˆ**ï¼šè‡ªåŠ¨ç”Ÿæˆè¶…å‚æ•°æ–‡æ¡£
3. **ä¾èµ–åˆ†æ**ï¼šå‘ç°ä¾èµ–åº“ä¸­çš„è¶…å‚æ•°ï¼Œç»Ÿä¸€ç®¡ç†
4. **ä»£ç å®¡æŸ¥**ï¼šæ£€æŸ¥è¶…å‚æ•°ä½¿ç”¨æ˜¯å¦è§„èŒƒ
